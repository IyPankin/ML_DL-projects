{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3zbLLaSGH6Z"
      },
      "source": [
        "## Лабораторная работа \"Введение в ML\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3v975uGH6h"
      },
      "source": [
        "В этой лабораторной вы:\n",
        "\n",
        "- познакомитесь с базовыми библиотеками для работы с табличными данными — `numpy` и `pandas`\n",
        "- поближе посмотрите на простейшие задачи машинного обучения: классификацию и регрессию\n",
        "- попробуете несколько метрик и поймёте, почему выбор метрики это важно\n",
        "- обучите несколько простых моделей\n",
        "- увидите связь между сложностью модели и переобучением\n",
        "- убедитесь, что без данных всё тлен"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad3nBqBSGH6j"
      },
      "source": [
        "Загрузка самых базовых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z8Iht5qhGH6l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W8Eq0sTGH6n"
      },
      "source": [
        "### [NumPy](https://numpy.org/doc/stable/user/index.html)\n",
        "\n",
        "С 1995 numeric, с 2006 NumPy — «Numerical Python extensions» или просто «NumPy»\n",
        "\n",
        "Возможности библиотеки NumPy:\n",
        "* работать с многомерными массивами (таблицами)\n",
        "* быстро вычислять математические функций на многомерных массивах\n",
        "\n",
        "Ядро пакета NumPy — объект [ndarray](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)\n",
        "\n",
        "**Важные отличия** между NumPy arrays и Python sequences:\n",
        "* NumPy array имеет фиксированную длину, которая определяется в момент его создания (в отличие от Python lists, которые могут расти динамически)\n",
        "* Элементы в NumPy array должны быть одного типа\n",
        "* Можно выполнять операции непосредственно над NumPy arrays\n",
        "\n",
        "**Скорость** NumPy достигается с помощью:\n",
        "* реализации на C\n",
        "* векторизации и броадкастинга (broadcasting). Например, произведение массивов совместимых форм.\n",
        "\n",
        "Теперь давайте разберёмся подробнее и сделаем что-нибудь приятное и полезное в `numpy`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS3UKcU6GH6o"
      },
      "source": [
        "### Индексация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqBzoEfvGH6p"
      },
      "source": [
        "В NumPy работает привычная индексация Python, ура! Включая использование отрицательных индексов и срезов (slices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anq_nSYTGH6q"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "<b>Замечание 1:</b> Индексы и срезы в многомерных массивах не нужно разделять квадратными скобками,\n",
        "т.е. вместо <b>matrix[i][j]</b> нужно использовать <b>matrix[i, j]</b>. Первое тоже работает, но сначала выдаёт строку i, потом элемент j в ней.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoHXSVIrGH6q"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "<b>Замечание 2:</b> Срезы в NumPy создают view, а не копии, как в случае срезов встроенных последовательностей Python (string, tuple and list).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YJKxBB4dGH6s",
        "outputId": "ee56f26f-cc62-4f74-8edb-86b93e90f823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "ones_matrix = np.ones((5, 5))\n",
        "ones_submatrix_view = ones_matrix[::2,::2] # creates a view, not copy\n",
        "ones_matrix[::2,::2] = np.zeros((3, 3))\n",
        "ones_submatrix_view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpEF1rp2GH6v"
      },
      "source": [
        "### Ссылка на Яндекс.Контест\n",
        "\n",
        "Решения и ответы в задачах, расположенных ниже, загружайте в контест на автоматическую проверку:\n",
        "https://new.contest.yandex.ru/60376/start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZpuxPhJGH6v"
      },
      "source": [
        "**1.** Реализуйте функцию, принимающую на вход два одномерных массива `first_array` и `second_array` и возвращающую матрицу, в которой первый массив соответствует первому столбцу матрицы, второй — второму.\n",
        "\n",
        "Вероятно первое, что приходит вам на ум, это конкатенация и транспонирование:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hmQk1N6rGH6w"
      },
      "outputs": [],
      "source": [
        "def construct_matrix(first_array, second_array):\n",
        "    \"\"\"\n",
        "    Construct matrix from pair of arrays\n",
        "    :param first_array: first array\n",
        "    :param second_array: second array\n",
        "    :return: constructed matrix\n",
        "    \"\"\"\n",
        "    return np.column_stack([first_array, second_array]) # <- your first right code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "id": "TeFqyCz4GH6x",
        "outputId": "93b74f7b-5c4e-4a68-da4a-1594ebe2389d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 3],\n",
              "       [2, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "construct_matrix(np.array([1,2]),np.array([3,4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP-lmcA2GH6y"
      },
      "source": [
        "(в скобках заметим, что конкатенировать можно vertically, horizontally, depth wise методами vstack, hstack, dstack по трём осям (0, 1 и 2, соотвественно), либо в общем случае `np.concatenate` — поиграйтесь ниже с прекрасным примером четырёхмерной точки, чтобы точно всё для себя понять)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xguxLJ0VGH6y",
        "outputId": "3add84a6-2b78-401c-ffc0-50f5e1b5d147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "p = np.arange(1).reshape([1, 1, 1, 1])\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z1JFw75eGH6y",
        "outputId": "0cfa1431-27c7-40e0-fac4-c151a3108ee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vstack:  (2, 1, 1, 1)\n",
            "hstack:  (1, 2, 1, 1)\n",
            "dstack:  (1, 1, 2, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"vstack: \", np.vstack((p, p)).shape)\n",
        "print(\"hstack: \", np.hstack((p, p)).shape)\n",
        "print(\"dstack: \", np.dstack((p, p)).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cvbthbDDGH6z",
        "outputId": "e016d5c1-3047-4a46-dc22-b8a9fa92cf02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "np.concatenate((p, p), axis=3).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5GkuWwaGH60"
      },
      "source": [
        "Но, поскольку операция транспонирования [делает массив non-contiguous](https://numpy.org/doc/stable/user/basics.copies.html#other-operations), мы в этой задаче **запретим** ей пользоваться и порекомедуем воспользоваться, например, методом [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ce_o75GH61"
      },
      "source": [
        "**2.** Реализуйте функцию, принимающую на вход массив целых неотрицательных чисел `nums` и возвращающую самый частый элемент массива."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XZysMovaGH61"
      },
      "outputs": [],
      "source": [
        "def most_frequent(nums):\n",
        "    \"\"\"\n",
        "    Find the most frequent value in an array\n",
        "    :param nums: array of ints\n",
        "    :return: the most frequent value\n",
        "    \"\"\"\n",
        "    unique, counts = np.unique(nums, return_counts=True)\n",
        "    max_id = np.argmax(counts)\n",
        "    return nums[max_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6kjITZMGH62"
      },
      "source": [
        "### Переходим к работе с данными\n",
        "\n",
        "Прежде всего, загрузим данные и сделаем из них красивые pandas-таблички. Они взяты из параллели RecSys соревнования https://yandex.ru/cup/ml/. Но мы будем иметь дело не со всеми данными, а только с их частью. Данные у нас будут про заведения общественного питания (больше бюрократический терминологии!)\n",
        "\n",
        "Файлы с данными можно найти [здесь](https://disk.yandex.ru/d/YWvCNRQMb7QSQA).\n",
        "\n",
        "Задачей будет **предсказание среднего чека** (average_bill) по некоторым другим свойствам заведения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yJPF3OclGH62"
      },
      "outputs": [],
      "source": [
        "base = '/content/sample_data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uzDIu6uXGH62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "b99d47f3-f95d-41d6-acf6-d8ad3c537cc2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/sample_data/organisations.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4171756916.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'organisations.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrubrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'rubrics.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/organisations.csv'"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(base + 'organisations.csv')\n",
        "features = pd.read_csv(base + 'features.csv')\n",
        "rubrics = pd.read_csv(base + 'rubrics.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-AwDM7bGH63"
      },
      "source": [
        "В основном мы будем работать с табличкой `data`; остальное вам может пригодиться, если вы захотите знать, какое содержание стоит за кодами признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hrvEN_3GH63"
      },
      "source": [
        "## Изучение данных"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vxtmFzL2uzZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI9YQMuCGH63"
      },
      "source": [
        "Посмотрите на данные. В этом вам поможет метод ``head`` pandas-таблички."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA_0DG29GH64"
      },
      "outputs": [],
      "source": [
        "# <Your code here>\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN9kZbURGH64"
      },
      "source": [
        "Полезно посмотреть внимательнее на то, с какими признаками нам предстоит работать.\n",
        "\n",
        "* **org_id** вам не понадобится;\n",
        "* **city** - город, в котором находится заведение (``msk`` или ``spb``);\n",
        "* **average_bill** - средний чек в заведении - он будет нашим таргетом;\n",
        "* **rating** - рейтинг заведения;\n",
        "* **rubrics_id** - тип заведения (или несколько типов). Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``rubrics``\n",
        "* **features_id** - набор неких фичей заведения. Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``features``\n",
        "\n",
        "Обратите внимание, что **rubrics_id** и **features_id** - это не списки, а разделённые пробелами строки. Когда вам захочется работать с отдельными фичами из мешка фичей для данного заведения, вам придётся всё-таки превратить их в списки (здесь поможет метод `split` для строк)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0IJIWz3GH64"
      },
      "source": [
        "Чтобы быстро восстанавливать по рубрикам и фичам их нормальные названия, сделайте словари вида ``код_фичи:название_фичи``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KwKEKr7GH65"
      },
      "outputs": [],
      "source": [
        "# <Your code here>\n",
        "rubric_dict = rubrics.set_index('rubric_id')['rubric_name'].to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNd4PkyQGH65"
      },
      "source": [
        "Посмотрим, какими бывают типы заведений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "8WhaPPEeGH65"
      },
      "outputs": [],
      "source": [
        "rubric_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA6Bm_8EGH66"
      },
      "source": [
        "Мы что-то поняли про признаки, которыми нам предстоит пользоваться. Теперь время посмотреть на таргет. Вооружившись функциями ``hist`` и ``scatter`` из библиотеки ``matplotlib``, а также методом ``isna`` для pandas-таблиц разберитесь, какие значения принимают таргеты, есть ли там там выбросы, пропуски или ещё какие-то проблемы.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    <ol>\n",
        "      <li>Среди таргетов довольно много пропусков;</li>\n",
        "      <li>Все таргеты - это числа, кратные 500;</li>\n",
        "      <li>Есть какие-то адские значения, превышающие 100 000 (видимо, выбросы);</li>\n",
        "      <li>В целом, число ресторанов с данным средним чеком быстро падает с ростом среднего чека. Для средних чеков, больших 2500, заведений уже совсем мало. Примерно у 2/3 заведений средний чек 500.</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['average_bill'].isna().sum())"
      ],
      "metadata": {
        "id": "q4LhR2Qhdd5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "f6bg-kmIGH66"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trfl5F_4GH66"
      },
      "source": [
        "**Базовая очистка данных**\n",
        "\n",
        "Раз есть треш, давайте чистить данные.\n",
        "\n",
        "С пропусками можно бороться по-разному (даже и с пропусками в таргете), но пока мы сделаем самую простую вещь: дропнем все заведения, для которых мы не знаем средний чек.\n",
        "\n",
        "Уберите из них все заведения, у которых средний чек неизвестен или превышает 2500. Пока есть опасение, что их слишком мало, чтобы мы смогли обучить на них что-нибудь.\n",
        "\n",
        "**3. Введите в Контест количество заведений, которое у вас получилось после очистки**.\n",
        "\n",
        "Дальше мы будем работать с очищенными данными."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxIkRsA1GH67"
      },
      "outputs": [],
      "source": [
        "# <Your code here>\n",
        "filtered_data = data.dropna(subset=['average_bill'])\n",
        "filtered_data = filtered_data[filtered_data['average_bill'] <= 2500]\n",
        "print(len(filtered_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_data.head())"
      ],
      "metadata": {
        "id": "X189sGESgiwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsNzGAp1GH67"
      },
      "source": [
        "**4. Посчитайте и введите в Контест разность между средними арифметическими average_bill в кафе Москвы и Санкт-Петербурга. Округлите ответ до целого.**\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Небольшая подсказка</summary>\n",
        "  Примените часто используемый метод groupby.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLdl3zVCGH67"
      },
      "outputs": [],
      "source": [
        "# <Your code here>\n",
        "cafe_data = filtered_data[filtered_data['rubrics_id'].str.contains('30774', na=False)]\n",
        "grouped_data = cafe_data.groupby('city')['average_bill'].mean()\n",
        "msk_avg = grouped_data.get('msk', 0)\n",
        "spb_avg = grouped_data.get('spb', 0)\n",
        "difference = round(msk_avg - spb_avg)\n",
        "print(difference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qncnmi8bGH7F"
      },
      "source": [
        "Давайте ещё немного поизучаем данные. Ответьте на вопросы:\n",
        "\n",
        "1. Есть ли разница между средними чеками в Москве и Санкт-Петербурге?\n",
        "2. Коррелирует ли средний чек с рейтингом?\n",
        "3. Есть ли разница в среднем чеке между ресторанами и пабами (см. соответствующие типы из ``rubrics``)?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    <ol>\n",
        "      <li>В целом, да. Вы могли бы сравнить средние (в Москве больше) или медианы (они равны, потому что уж больно много где средний чек 500). Этого, конечно, мало для того, чтобы сделать вывод. Нужно проверять какие-то статические критерии, которые изучаются в курсе по статистике. Не будем останавливаться на этом подробно. Поскольку данные совсем не нормальные, никакой t-тест не сработает; мы бы предложили использовать критерий Манна-Уитни (см. википедию и функцию mannwhitneyu из библиотеки scipy.stats).</li>\n",
        "      <li>Какая-то корреляция между ними есть но уж больно неубедительная (рекомендуем построим на одном графике boxplot рейтинга по каждому значению среднего чека для визуализации). Конечно, дна становится меньше с ростом среднего чека, но, видимо, в предсказании это особо не используешь;</li>\n",
        "      <li>Несомненно, в ресторанах средний чек выше. Это и невооружённым глазом видно, и с помощью критерия Манна-Уитни можно проверить.</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATY5075lGH7F"
      },
      "source": [
        "## Формулируем задачу"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znpEgJGIGH7F"
      },
      "source": [
        "Прежде, чем решать задачу, её надо сформулировать.\n",
        "\n",
        "**Вопрос первый**: это классификация или регрессия? Подумайте над этим.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    Ответ не столь однозначен, как хотелось бы. С одной стороны, таргет принимает всего четыре значения, и потому это может быть классификацией с 4 классами. С другой стороны, таргеты - это не абстрактные \"треугольник\", \"круг\", \"квадрат\", а вещественные числа, и когда мы вместо 500 предсказываем 2500, это явно хуже, чем вместо 1500 предсказать 2000. В целом, задачу можно решать и так, и так; мы будем смотреть на метрики обеих задач.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaVuazxsGH7G"
      },
      "source": [
        "**Вопрос второй**: какие метрики мы будем использовать для оценки качества решения? Какие метрики вы предложили бы для этой задачи как для задачи классификации? А для этой задачи, как для задачи регрессии?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "    Начнём с классификации. Метрика accuracy не очень хороша из-за несбалансированности классов. Действительно, классификатор, который всегда говорит 500, будет иметь accuracy примерно 0.66, хотя это никак не отражает практическую ценность модели. Как мы увидим, самая большая проблема будет заключаться в том, чтобы научиться выделять заведения с большими чеками, а их меньше всего и в accuracy они вносят самый маленький вклад. Есть разные способы с этим бороться, один -- использовать sklearn.metrics.balanced_accuracy_score. Его идея, грубо говоря, в том, чтобы по каждому классу найти, какая доля объектов этого класса правильно классифицирована, а потом эти доли усреднить. Тогда у бессмысленного классификатора, который всем ставит 500, будет скор 1/5 (ведь классов 5), а чтобы получить прежние 2/3, нужно будет научиться в каждом классе правильно ставить хотя бы 2/3 меток.    \n",
        "    \n",
        "    Теперь что касается регрессии. Основых метрики две - MSE и MAE. Из первой стоит извлекать корень, чтобы получать интерпретируемые человеком значения, а вторая менее агрессивна к выбросам (впрочем, выбросов тут уже нет, мы их все выкинули). Без дополнительной информации не очень понятно, какую выбирать, можно брать любую. А выбирать надо: ведь даже банальные модели \"предсказывай всегда среднее\" и \"предсказывай всегда медиану\" будут по-разному ранжироваться этими метриками.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs-jkCj-GH7G"
      },
      "source": [
        "**Вопрос третий**: а не взять ли нам какую-нибудь более экзотическую метрику? Например, MAPE (определение в учебнике в главе про оценку качества моделей). А как вам такое соображение: допустим, заказчик говорит, что пользователи будут расстраиваться, только если мы завысили средний чек - так давайте поправим MSE или MAE, обнуляя те слагаемые, для которых предсказанный таргет меньше истинного. Вот это хорошая метрика или нет?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "    Что касается MAPE, у нас нет тех проблем, с которой она борется. Вот если бы у нас были средние чеки от 500 до миллиона, мы бы столкнулись с ситуацией, что большие ошибки для больших чеков доминировали бы в сумме для MSE и MAE (500 вместо 1000 меркнет по сравнению с 500к вместо миллиона). Говоря поэтически, мы бы оптимизировали модель для миллионеров, забыв про простых трудяг. И было бы логично перейти от парадигмы \"ошибаемся на 500 рублей\" к парадигме \"ошибаемся на 50%\". Но у нас все таргеты примерно одного порядка, MAPE нам особо ни к чему.\n",
        "    \n",
        "    Вторая метрика коварна тем, что её можно \"накрутить\" безо всякой пользы для дела. А именно, модель, которая всегда предсказывает средний чек в миллион, была бы идеальна. Но все бы расстраивались и не ходили есть. Другое дело, что можно ввести разные веса для ошибок в большую и в меньшую сторону, но опять же - пока нет показаний к тому, что это нужно.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCjV_SoAGH7G"
      },
      "source": [
        "## Применяем ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqkvcLSPGH7G"
      },
      "source": [
        "Теперь время разбить данные на обучающую и тестовую выборку. Делается это с помощью функции ``train_test_split`` из пакета ``sklearn``. При этом очень важно сделать две вещи:\n",
        "\n",
        "* Зафиксировать ``random_state=42`` (да, именно этот, а то ваши модели могут не зайти в Контест), чтобы всё, что мы делаем, было воспроизводимо (иначе от перезапуска к перезапуску числа могут меняться, и мы не будем понимать, из-за чего это происходит).\n",
        "* Сделать стратификацию по таргету. В противном случае у нас в трейне и тесте могут оказаться разные пропорции классов (обычно особенно страдают мало представленные классы), что неутешительно скажется на результате.\n",
        "\n",
        "**Обратите внимание**, что если вы побьёте выборку на train и test по-другому, ваши результаты могут не зайти в контест."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF2IVpOjGH7H"
      },
      "outputs": [],
      "source": [
        "clean_data_train, clean_data_test = train_test_split(\n",
        "    filtered_data, stratify=filtered_data['average_bill'], test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S161veFJGH7H"
      },
      "source": [
        "Теперь нам нужен **бейзлайн** - очень простая модель, с которой мы в дальнейшем будем сравниваться.\n",
        "\n",
        "Поскольку мы ещё не знаем никаких умных классов моделей, все модели мы будем писать руками. А именно, мы напишем две простых модели на основе ``sklearn.baseRegressorMixin`` и ``sklearn.base.ClassifierMixin`` (посмотрите примеры в документации sklearn и сделайте так же):\n",
        "\n",
        "* Модель для задачи регрессии, которая для всех заведений предсказывает одно число — среднее значение среднего чека;\n",
        "* Модель для задачи классификации, которая для всех заведений предсказывает один класс — самый частый класс (ироничным образом он в данном случае совпадает с медианой).\n",
        "\n",
        "**Важно!** Мы будем много раз повторять вам мантру о том, что **информация из тестовой выборки не должна протекать в процесс обучения**. Так вот, и среднее, и самый частый класс вы должны считать именно на обучающей выборке!\n",
        "\n",
        "**5 и 6. Напишите эти две модели и сдайте в Контест**. В процессе проверки модели будут и обучаться, и предсказывать.\n",
        "\n",
        "Заметим, что для этих моделей нам вообще не нужны какие-то \"фичи\"; мы работаем только с таргетом.\n",
        "\n",
        "У каждой модели есть (как минимум) два метода: `fit` (обучает модель по фичам `X` и таргету `y`) `predict` (предсказывает по фичам `X`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLz_sxtUGH7H"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "from sklearn.base import RegressorMixin, ClassifierMixin\n",
        "import numpy as np\n",
        "\n",
        "class MeanRegressor(RegressorMixin):\n",
        "    # Predicts the mean of y_train\n",
        "    def fit(self, X=None, y=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Training data features\n",
        "        y : array like, shape = (_samples,)\n",
        "        Training data targets\n",
        "        '''\n",
        "        self.mean_ = np.mean(y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Data to predict\n",
        "        '''\n",
        "        n_samples = X.shape[0] if hasattr(X, 'shape') else len(X)\n",
        "        return np.full(n_samples, self.mean_)\n",
        "\n",
        "from sklearn.base import ClassifierMixin\n",
        "import numpy as np\n",
        "from scipy.stats import mode\n",
        "\n",
        "class MostFrequentClassifier(ClassifierMixin):\n",
        "    # Predicts the rounded (just in case) median of y_train\n",
        "    def fit(self, X=None, y=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Training data features\n",
        "        y : array like, shape = (_samples,)\n",
        "        Training data targets\n",
        "        '''\n",
        "        if len(y) == 0:\n",
        "            self.most_frequent_ = None\n",
        "        else:\n",
        "            mode_result = mode(y)\n",
        "            # Check if the mode result is a scalar or an array\n",
        "            if np.isscalar(mode_result.mode):\n",
        "                self.most_frequent_ = mode_result.mode\n",
        "            elif mode_result.mode.size > 0: # Check if the mode result array is not empty\n",
        "                self.most_frequent_ = mode_result.mode[0]\n",
        "            else:\n",
        "                # Handle the case where mode doesn't return a mode (e.g., all elements are unique)\n",
        "                # In this case, we can just take the first element as a fallback or handle as appropriate\n",
        "                self.most_frequent_ = y.iloc[0] if hasattr(y, 'iloc') else y[0]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Data to predict\n",
        "        '''\n",
        "        n_samples = X.shape[0] if hasattr(X, 'shape') else len(X)\n",
        "        if self.most_frequent_ is None:\n",
        "            return np.empty(n_samples) # Or handle as appropriate for no frequent value\n",
        "        else:\n",
        "            return np.full(n_samples, self.most_frequent_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo2pNhVoGH7I"
      },
      "source": [
        "Обучим наши модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arXlaGnTGH7I"
      },
      "outputs": [],
      "source": [
        "reg = MeanRegressor()\n",
        "reg.fit(y=clean_data_train['average_bill'])\n",
        "reg_pred = reg.predict(X=clean_data_test)\n",
        "\n",
        "clf = MostFrequentClassifier()\n",
        "clf.fit(y=clean_data_train['average_bill'])\n",
        "clf_pred = clf.predict(X=clean_data_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fef9bfcd"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, balanced_accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate RMSE for the regressor\n",
        "reg_rmse = np.sqrt(mean_squared_error(clean_data_test['average_bill'], reg_pred))\n",
        "print(f\"MeanRegressor RMSE: {reg_rmse}\")\n",
        "\n",
        "# Calculate RMSE and balanced accuracy for the classifier\n",
        "clf_rmse = np.sqrt(mean_squared_error(clean_data_test['average_bill'], clf_pred))\n",
        "clf_balanced_accuracy = balanced_accuracy_score(clean_data_test['average_bill'], clf_pred)\n",
        "\n",
        "print(f\"MostFrequentClassifier RMSE: {clf_rmse}\")\n",
        "print(f\"MostFrequentClassifier Balanced Accuracy: {clf_balanced_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJG8x0tmGH7I"
      },
      "source": [
        "Обучите модели и оцените их качество на тестовой выборке. В качестве метрик возьмём RMSE (``np.sqrt`` от ``sklearn.metrics.mean_squared_error``) и ``sklearn.metrics.balanced_accuracy_score``.\n",
        "\n",
        "Для регрессионной модели имеет смысл считать только RMSE (значения будут не кратны 500, точно мы угадывать не будем никогда), а вот для классификационной можно найти обе метрики. Сделайте это. Какая модель оказалась лучше по RMSE?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvZwp54sGH7J"
      },
      "source": [
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда</summary>\n",
        "    \n",
        "  Казалось бы, регрессор никогда не угадывает, но он в каком-то смысле лучше классификатора - справедливо ли это? Возможно. Несуществующий пользователь модели вряд ли будет задавать вопросы \"почему средний чек не кратен 500?\" Ну, выдали около 800 - ок, понятно.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-1-O9GyGH7J"
      },
      "source": [
        "## Усложнение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGWgxl0VGH7J"
      },
      "source": [
        "Бейзлайны будут нашей отправной точкой. Строя дальнейшие модели, мы будем спрашивать себя: получилось ли лучше бейзлайна? Если нет или если не особо, то в чём смысл усложнения?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w3DkuuFGH7K"
      },
      "source": [
        "Начнём с использования фичи ``city``. Мы уже видели, что в разных городах и средние чеки разные. Легко проверить, что *медиана* средних чеков всё же одна и та же и в Москве, и в Санкт-Петербурге (ох уж этот вездесущий средний чек 500!), поэтому с классификатором мы ничего не сделаем. Но вот регрессор можно попробовать починить.\n",
        "\n",
        "**7. Напишите регрессор, для каждого заведения предсказывающий среднее значение в том же городе (на обучающей выборке, конечно) и сдайте его в Контест**. Вам может помочь то, что булевы `pandas` и `numpy` столбцы можно умножать на численные — в такой ситуации False работает, как ноль, а True как единица."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZULQVPe2GH7K"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import RegressorMixin\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class CityMeanRegressor(RegressorMixin):\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pandas DataFrame, shape = (n_samples, n_features)\n",
        "        Training data features (must include 'city' column)\n",
        "        y : pandas Series, shape = (_samples,)\n",
        "        Training data targets\n",
        "        '''\n",
        "        if 'city' not in X.columns:\n",
        "            raise ValueError(\"Input DataFrame X must contain a 'city' column.\")\n",
        "\n",
        "        train_data = X.copy()\n",
        "        train_data['average_bill'] = y\n",
        "        self.city_means_ = train_data.groupby('city')['average_bill'].mean().to_dict()\n",
        "        self.global_mean_ = np.mean(y) # Fallback for cities not seen during training\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pandas DataFrame, shape = (n_samples, n_features)\n",
        "        Data to predict (must include 'city' column)\n",
        "        '''\n",
        "        if 'city' not in X.columns:\n",
        "            raise ValueError(\"Input DataFrame X must contain a 'city' column.\")\n",
        "\n",
        "        predictions = X['city'].apply(lambda city: self.city_means_.get(city, self.global_mean_))\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EeFGk24GH7K"
      },
      "source": [
        "Обучите регрессор и сравните его по метрике RMSE с бейзлайнами. Получилось ли улучшить метрику?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jROycei1GH7L"
      },
      "source": [
        "Лучше стало, но, правда, не очень сильно. В этот момент очень важно не просто радовать руководителя приростом в третьем знаке, но и думать о том, что происходит.\n",
        "\n",
        "Средний средний чек по Москве равен 793, в Санкт-Петербурге - 676, а в целом - 752 рубля. MSE, увы, не поможет вам ответить на вопрос, стало ли лучше пользователю, если вы ему вместо 752 рублей назвали 793. Здесь вскрывается весьма существенный порок MSE в этой задаче. Дело в том, что наш изначальный таргет делит заведения на некоторые \"ценовые категории\", и различие в средних чеках 500 и 1000 в самом деле существенно. Наверное, мы хотели бы как раз правильно предсказывать ценовые категории. Но MSE не очень помогает нам об этом судить. Дальше мы ещё подумаем, как это исправить.\n",
        "\n",
        "В любом случае, несмотря на улучшение метрики, мы пока не можем судить, стало ли по жизни лучше от усложнения модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEQ9eOoWGH7L"
      },
      "source": [
        "Поручинившись немного, возьмём на вооружение другую идею. Давайте использовать типы заведений!\n",
        "\n",
        "Но с типами есть некоторая проблема: в столбце ``rubrics_id`` не всегда один идентификатор, часто их несколько, и всего комбинаций довольно много. Чтобы не возиться с малочисленными типами, давайте сольём их в один безликий ``other``.\n",
        "\n",
        "Итак, добавьте в обучающие и тестовые данные столбец ``modified_rubrics``, в котором будет то же, что и в ``rubrics_id``, если соответствующая комбинация рубрик содержит хотя бы 100 заведений из обучающей (!) выборки, и строка ``other`` в противном случае.\n",
        "\n",
        "Здесь вам поможет контейнер ``Counter`` из библиотеки ``collections``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTVW5KkwGH7L"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count occurrences of each rubrics_id in the training data\n",
        "rubric_counts = Counter(clean_data_train['rubrics_id'])\n",
        "\n",
        "# Identify rubrics_id combinations that appear less than 100 times\n",
        "rare_rubrics = {rubric for rubric, count in rubric_counts.items() if count < 100}\n",
        "\n",
        "# Create the modified_rubrics column in the training data\n",
        "clean_data_train['modified_rubrics'] = clean_data_train['rubrics_id'].apply(\n",
        "    lambda x: 'other' if x in rare_rubrics else x\n",
        ")\n",
        "\n",
        "# Create the modified_rubrics column in the testing data\n",
        "clean_data_test['modified_rubrics'] = clean_data_test['rubrics_id'].apply(\n",
        "    lambda x: 'other' if x in rare_rubrics else x\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZXhpBjnGH7L"
      },
      "source": [
        "Теперь настало время написать могучий классификатор, который по заведению предсказывает медиану средних чеков среди тех в обучающей выборке, у которых с ним одинаковые `modified_rubrics` и город (вы спросите, почему медиану, а не самый частый -- спишем это на вдохновение; самый частый тоже можно брать - но медиана работает лучше).\n",
        "\n",
        "**8. Напишите классификатор и сдайте в Контест**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTfcwh5dGH7M"
      },
      "outputs": [],
      "source": [
        "# your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbgjbwgkGH7M"
      },
      "source": [
        "Сравните обученный классификатор по метрикам RMSE и balanced_accuracy_score с нашими бейзлайнами. Получилось ли улучшить?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMjsnCnQGH7M"
      },
      "source": [
        "Обратите внимание что рост accuracy по сравнению с бейзлайном при этом на порядок меньше:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2cF0I-CGH7M"
      },
      "source": [
        "accuracy_score\n",
        "\n",
        "Predict most frequent:  0.6947666195190948\n",
        "\n",
        "Predict by rubric and city:  0.7095709570957096"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylrAIjCcGH7N"
      },
      "source": [
        "Для диагностики напечатайте для каждого класса тестовой выборки, сколько в нём объектов и скольким из них наш классификатор приписал правильный класс. Что вы видите?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "  Вы, вероятно, видите то, что мы стали однозначно лучше по сравнению с бейзлайном детектировать средний чек 1000 и 1500 (хотя всё равно не очень хорошо + ценой ухудшения качества на среднем чеке 500), а вот чеки 2000 и 2500 нам ну никак не даются.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ScOy7ZvGH7N"
      },
      "source": [
        "**Кстати**. А вы понимаете, почему приведённый выше пайплайн классификации был не очень удачным с точки зрения архитектуры? Почему его было бы правильнее воплотить по-другому?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "Собственно говоря, и не было никакого пайплайна. К счастью, у нас была одна обучающая выборка, мы на ней посчитали список рубрик для modified_rubrics и радовались жизни. Но если бы нам надо было переобучать всё на новых данных, пришлось бы помнить, что их надо везде пересчитать (ведь у нас могли появиться новые рубрики с хотя бы 100 представителями). А уж никакую кросс-валидацию (кто знает - тот поймёт) с нашим подходом к делу и вовсе бы не получилось сделать без боли.\n",
        "    \n",
        "Поэтому в следующей лабораторной вы научитесь делать честные пайплайны, в которых преобразование данных, генерация фичей и обучение классификатора будут объединены в один понятный процесс, происходящий на этапе fit.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ujl3tbbGH7N"
      },
      "source": [
        "## Слишком простые и слишком сложные модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF7McCHsGH7N"
      },
      "source": [
        "Бейзлайны у нас слишком просты и потому не очень полезны в жизни. Но если сложность модели растёт бесконтрольно, то тоже получается плохо.\n",
        "\n",
        "Давайте рассмотрим конкретный пример. Создадим классификатор, использующий одновременно `rubrics_id` и `features_id`.\n",
        "\n",
        "Сделайте следующее:\n",
        "\n",
        "- для каждого объекта обучающей выборки сконкатенируйте строку `rubrics_id` с разделителем (например, буквой 'q') и содержимым `features_id`. Полученный столбец озаглавьте `modified_features`. Это не самый клёвый способ заиспользовать все фичи, но сейчас пока сойдёт. Причём на сей раз не будем выкидывать мало представленные значения (вся информация важна, не так ли?).\n",
        "- при этом для тестовой выборке заменяйте на строку `other` все конкатенации, которые не встретились в обучающей выборке.\n",
        "\n",
        "То есть элементы в этом столбце будут иметь вид `other` или `30776 30774 q 3502045032 11741 3502045016 1046...`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8tNBPzVGH7O"
      },
      "source": [
        "Теперь обучите классификатор, который для заведения предсказывает медиану среднего чека по всем объектам тестовой выборки с таким же, как у него, значением `modified_features`, а если такого в обучающей выборке нет, то глобальную медиану среднего чека по всей обучающей выборке.\n",
        "\n",
        "**9. Загрузите в Контест предсказания этого классификатора на тестовой выборке**\n",
        "\n",
        "Мы ждём файла **.csv**, у которого в каждой строке будет только одно число - предсказание классификатора.\n",
        "\n",
        "Возможно, вам будет полезна библиотека ``tqdm``, позволяющая отслеживать в реальном времени, сколько времени уже крутится цикл и сколько итераций ещё осталось. Впрочем, если вы всё написали нормально, то должно работать не очень долго."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XrswPW4GH7O"
      },
      "source": [
        "Модель, очевидно, очень сложная. Число параметров (различных категорий) в ней сопоставимо с числом объектов в обучающей выборке. А получилось ли хорошо?\n",
        "\n",
        "Давайте посчитаем RMSE и balanced_accuracy_score на обучающей и на тестовой выборках.\n",
        "\n",
        "**10. Введите их в Контест**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGDTpxFgGH7O"
      },
      "source": [
        "Налицо переобучение: на трейне метрики отличные, на тесте - вообще никакие\n",
        "\n",
        "В общем, не гонитесь за чрезмерной сложностью модели.."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.base import ClassifierMixin\n",
        "\n",
        "# Create the modified_features column for training data\n",
        "clean_data_train['modified_features'] = clean_data_train['rubrics_id'] + 'q' + clean_data_train['features_id']\n",
        "\n",
        "# Get unique modified_features from training data\n",
        "train_features = set(clean_data_train['modified_features'].unique())\n",
        "\n",
        "# Create the modified_features column for testing data, replacing unseen with 'other'\n",
        "clean_data_test['modified_features'] = clean_data_test.apply(\n",
        "    lambda row: row['rubrics_id'] + 'q' + row['features_id'] if (row['rubrics_id'] + 'q' + row['features_id']) in train_features else 'other',\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "class ModifiedFeaturesMedianClassifier(ClassifierMixin):\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pandas DataFrame, shape = (n_samples, n_features)\n",
        "        Training data features (must include 'modified_features' column)\n",
        "        y : pandas Series, shape = (_samples,)\n",
        "        Training data targets\n",
        "        '''\n",
        "        if 'modified_features' not in X.columns:\n",
        "            raise ValueError(\"Input DataFrame X must contain a 'modified_features' column.\")\n",
        "\n",
        "        train_data = X.copy()\n",
        "        train_data['average_bill'] = y\n",
        "        self.feature_medians_ = train_data.groupby('modified_features')['average_bill'].median().to_dict()\n",
        "        self.global_median_ = np.median(y) # Fallback for unseen features\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pandas DataFrame, shape = (n_samples, n_features)\n",
        "        Data to predict (must include 'modified_features' column)\n",
        "        '''\n",
        "        if 'modified_features' not in X.columns:\n",
        "            raise ValueError(\"Input DataFrame X must contain a 'modified_features' column.\")\n",
        "\n",
        "        if X['modified_features'].empty:\n",
        "            print(\"Warning: 'modified_features' column in prediction data is empty.\")\n",
        "            return pd.Series([], dtype=float) # Return an empty Series\n",
        "\n",
        "        predictions = X['modified_features'].apply(lambda feature: self.feature_medians_.get(feature, self.global_median_))\n",
        "        return predictions\n",
        "\n",
        "# Train the classifier\n",
        "mf_clf = ModifiedFeaturesMedianClassifier()\n",
        "mf_clf.fit(X=clean_data_train, y=clean_data_train['average_bill'])\n",
        "\n",
        "# Make predictions on the test set\n",
        "mf_clf_pred = mf_clf.predict(X=clean_data_test)\n",
        "\n",
        "# Add print statements to check the predictions before saving\n",
        "print(f\"Shape of predictions Series: {mf_clf_pred.shape}\")\n",
        "print(\"Predictions head:\")\n",
        "print(mf_clf_pred.head())\n",
        "\n",
        "# Format predictions as \"index,prediction\" strings\n",
        "formatted_predictions = [f\"{index},{prediction}\" for index, prediction in mf_clf_pred.items()]\n",
        "\n",
        "# Save formatted predictions to a text file\n",
        "with open('modified_features.txt', 'w') as f:\n",
        "    for line in formatted_predictions:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(\"Predictions saved to modified_features.txt\")"
      ],
      "metadata": {
        "id": "R9DCj9Znt27B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read from the text file and parse index and prediction\n",
        "data_from_txt = []\n",
        "with open('modified_features.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        index, prediction = line.strip().split(',')\n",
        "        data_from_txt.append({'index': int(index), 'average_bill': float(prediction)})\n",
        "\n",
        "# Convert to DataFrame and save to CSV\n",
        "predictions_df = pd.DataFrame(data_from_txt)\n",
        "# Set the 'index' column as the DataFrame index\n",
        "predictions_df = predictions_df.set_index('index')\n",
        "predictions_df.to_csv('modified_features.csv', index=True, header=False)\n",
        "\n",
        "print(\"Predictions saved to modified_features.csv\")"
      ],
      "metadata": {
        "id": "tctfpy9gxHKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, balanced_accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the training set\n",
        "mf_clf_train_pred = mf_clf.predict(X=clean_data_train)\n",
        "\n",
        "# Calculate metrics on the training set\n",
        "mf_clf_train_rmse = np.sqrt(mean_squared_error(clean_data_train['average_bill'], mf_clf_train_pred))\n",
        "mf_clf_train_balanced_accuracy = balanced_accuracy_score(clean_data_train['average_bill'], mf_clf_train_pred)\n",
        "\n",
        "# Calculate metrics on the test set (predictions are already available in mf_clf_pred)\n",
        "mf_clf_test_rmse = np.sqrt(mean_squared_error(clean_data_test['average_bill'], mf_clf_pred))\n",
        "mf_clf_test_balanced_accuracy = balanced_accuracy_score(clean_data_test['average_bill'], mf_clf_pred)\n",
        "\n",
        "# Print the results rounded to two decimal places\n",
        "print(f\"{mf_clf_train_rmse:.2f} {mf_clf_train_balanced_accuracy:.2f} {mf_clf_test_rmse:.2f} {mf_clf_test_balanced_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "Q1uSKi7dzmjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTU2yubYGH7O"
      },
      "source": [
        "## ML без данных что компутер без электричества"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBVOCVf2GH7P"
      },
      "source": [
        "Возможно, вы смотрите на полученные выше результаты и думаете: вот если бы мы не какие-то убогие медианы предсказывали, а гоняли бы нейросети, то тут-то бы всё и получилось!\n",
        "\n",
        "Но, увы, совсем даже не всегда от счастья нас отделяет выбор хорошей модели (и стратегии обучения). Если данные не очень, то даже самая крутая модель не сработает. В этой ситуации нужно либо добывать новые фичи каким-то образом, либо собирать новые данные (увеличивать датасет), либо просто бросать задачу.\n",
        "\n",
        "Давайте посмотрим, что выжмет из наших данных одна из самых мощных моделей для табличных данных - градиентный бустинг на решающих деревьях в исполнении [CatBoost](https://catboost.ai/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0L4UmzSGH7P"
      },
      "source": [
        "Но прежде, чем сделать fit, нам надо облагородить данные. Несмотря на то, что CatBoost отлично работает с категориальными фичами, мешок признаков из `rubrics_id` или `features_id` может ему оказаться не по зубам. Поэтому мы соберём датасет в пристойную матрицу, создав для каждого типа рубрик и фичей отдельный столбец и записав там единицы для тех объектов, у которых эта рубрика или фича имеет место.\n",
        "\n",
        "В матрице почти все элементы будут нулями. Такие матрицы считаются **разреженными** и их можно хранить гораздо эффективней, чем просто таблицей. Этим и займёмся)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJKuMtNbGH7P"
      },
      "source": [
        "Есть несколько форматов хранения разреженных матриц (многие из них реализованы в [пакете sparse библиотеки scipy](https://docs.scipy.org/doc/scipy/reference/sparse.html)), и каждый пригоден для чего-то своего.\n",
        "\n",
        "Создавать разреженную матрицу лучше в [формате COO](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_array.html#scipy.sparse.coo_array). Он предполагает, что разреженная матрица задаётся в виде трёх списков: `row`, `col`, `data`, причём каждая тройка `(row[i], col[i], data[i])` кодирует элемент со значением `data[i]`, стоящий на позиции `(row[i], col[i])`. Считается, что на позициях `(row, col)`, которые ни разу не встретились, стоят нули.\n",
        "\n",
        "Нетрудно видеть, что заполнять такую матрицу - одно удовольствие, и особенно этому помогает тот факт, что **пара `(row, col)` может встретиться несколько раз** (тогда в итоговой матрице на соответствующей позиции стоит сумма соответствующих `data[i]`). Но, с другой стороны, почти ничего другого с такой матрицей не сделаешь: произвольного доступа к элементам она не предоставляет, умножить её тоже особо ничего не умножишь. Поэтому для дальнейшего использования созданную таким образом матрицу преобразуют в один из более удобных форматов, например, [CSR (compressed sparse row)](https://scipy-lectures.org/advanced/scipy_sparse/csr_matrix.html). Он, к примеру, хорошо подходит для умножения на вектор (потому что матрица хранится по строкам). Не будем разбирать его подробно, но можете почитать по ссылке, если интересно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hd_Sob3GH7P"
      },
      "source": [
        "Вам нужно будет превратить обучающие и тестовые данные в разреженные матрицы `sparse_data_train` и `sparse_data_test` соответственно, таким образом, что:\n",
        "\n",
        "- столбец `city` превратится в столбец из единиц и нулей (например, 1 - Москва, 0 - Питер);\n",
        "- столбец `rating` перекочует в разреженные матрицы без изменений;\n",
        "- каждый типы рубрик и каждая фича превратятся в отдельный 0-1-принак;\n",
        "\n",
        "В тестовой выборке будут фичи, которых в обучающей выборке не было. С ними можно по-разному работать, но давайте создадим дополнительную фантомную фичу `feature_other`, в которой будет то, сколько неизвестных по обучающей выборке фичей есть у данного объекта."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-UAatGJGH7P"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import coo_matrix, hstack\n",
        "import numpy as np\n",
        "\n",
        "def create_sparse_features(df, all_rubrics, all_features):\n",
        "    \"\"\"\n",
        "    Creates sparse features from a DataFrame including city, rating, rubrics, and features_id.\n",
        "\n",
        "    Args:\n",
        "        df: Pandas DataFrame with 'city', 'rating', 'rubrics_id', and 'features_id' columns.\n",
        "        all_rubrics: A list of all unique rubric IDs from the training data.\n",
        "        all_features: A list of all unique feature IDs from the training data.\n",
        "\n",
        "    Returns:\n",
        "        A sparse matrix containing the features.\n",
        "    \"\"\"\n",
        "    n_samples = len(df)\n",
        "    row_indices = []\n",
        "    col_indices = []\n",
        "    data_values = []\n",
        "\n",
        "    # City feature (1 for msk, 0 for spb)\n",
        "    city_feature = (df['city'] == 'msk').astype(int).values\n",
        "    row_indices.extend(range(n_samples))\n",
        "    col_indices.extend([0] * n_samples)\n",
        "    data_values.extend(city_feature)\n",
        "\n",
        "    # Rating feature\n",
        "    # Handle potential NaN values in rating by replacing with a placeholder or mean/median\n",
        "    # For now, we'll fill NaN with 0, but a more sophisticated approach might be needed\n",
        "    rating_feature = df['rating'].fillna(0).values\n",
        "    row_indices.extend(range(n_samples))\n",
        "    col_indices.extend([1] * n_samples)\n",
        "    data_values.extend(rating_feature)\n",
        "\n",
        "    # Rubrics features\n",
        "    rubric_col_start = 2  # Start index for rubric features\n",
        "    rubric_id_to_col = {rubric_id: i + rubric_col_start for i, rubric_id in enumerate(all_rubrics)}\n",
        "\n",
        "    for i, rubrics_list in enumerate(df['rubrics_id'].str.split().fillna('')):\n",
        "        for rubric_id in rubrics_list:\n",
        "            if rubric_id in rubric_id_to_col:\n",
        "                row_indices.append(i)\n",
        "                col_indices.append(rubric_id_to_col[rubric_id])\n",
        "                data_values.append(1)\n",
        "\n",
        "    # Features_id features\n",
        "    features_col_start = rubric_col_start + len(all_rubrics)\n",
        "    feature_id_to_col = {feature_id: i + features_col_start for i, feature_id in enumerate(all_features)}\n",
        "    feature_other_col = features_col_start + len(all_features) # Column for 'feature_other'\n",
        "\n",
        "    for i, features_list in enumerate(df['features_id'].str.split().fillna('')):\n",
        "        unknown_feature_count = 0\n",
        "        for feature_id in features_list:\n",
        "            if feature_id in feature_id_to_col:\n",
        "                row_indices.append(i)\n",
        "                col_indices.append(feature_id_to_col[feature_id])\n",
        "                data_values.append(1)\n",
        "            else:\n",
        "                unknown_feature_count += 1\n",
        "        # Add 'feature_other' count\n",
        "        if unknown_feature_count > 0:\n",
        "             row_indices.append(i)\n",
        "             col_indices.append(feature_other_col)\n",
        "             data_values.append(unknown_feature_count)\n",
        "\n",
        "\n",
        "    # Create COO matrix\n",
        "    n_cols = 2 + len(all_rubrics) + len(all_features) + 1 # city, rating, rubrics, features, feature_other\n",
        "    sparse_matrix = coo_matrix((data_values, (row_indices, col_indices)), shape=(n_samples, n_cols))\n",
        "\n",
        "    return sparse_matrix.tocsr() # Convert to CSR format for efficient operations\n",
        "\n",
        "# Get all unique rubrics and features from the training data\n",
        "all_rubrics_train = sorted(list(set(rubric for rubrics_list in clean_data_train['rubrics_id'].str.split().fillna('') for rubric in rubrics_list)))\n",
        "all_features_train = sorted(list(set(feature for features_list in clean_data_train['features_id'].str.split().fillna('') for feature in features_list)))\n",
        "\n",
        "# Create sparse matrices for train and test data\n",
        "sparse_data_train = create_sparse_features(clean_data_train, all_rubrics_train, all_features_train)\n",
        "sparse_data_test = create_sparse_features(clean_data_test, all_rubrics_train, all_features_train)\n",
        "\n",
        "print(\"Sparse matrices created.\")\n",
        "print(f\"Shape of sparse_data_train: {sparse_data_train.shape}\")\n",
        "print(f\"Shape of sparse_data_test: {sparse_data_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFfj-1E4GH7Q"
      },
      "source": [
        "Данные готовы, и теперь можно запустить катбуст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2lP5NouGH7Q"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abfb06b4"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpW6uR0oGH7Q"
      },
      "outputs": [],
      "source": [
        "# <USE IT!>\n",
        "clf = CatBoostClassifier()\n",
        "clf.fit(sparse_data_train, clean_data_train['average_bill'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "catboost_test_pred = clf.predict(sparse_data_test)\n",
        "\n",
        "# Calculate balanced accuracy on the test set\n",
        "catboost_balanced_accuracy = balanced_accuracy_score(clean_data_test['average_bill'], catboost_test_pred)\n",
        "\n",
        "# Print the result rounded to two decimal places\n",
        "print(f\"{catboost_balanced_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "vy8Y_xVk2ZPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBOpZY9BGH7Q"
      },
      "source": [
        "**11. Пришлите в Контест balanced_accuracy_score на тестовой выборке, округлённый до двух знаков после запятой**. Стало ли сильно лучше от того, что мы воспользовались таким крутым классификатором?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}